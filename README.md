SEM Image Classification Pipeline

A lightweight, reproducible training pipeline for classifying Scanning Electron Microscopy (SEM) images of Niâ€‘rich NCM cathode materials (and derivatives) using a fineâ€‘tuned EfficientNetâ€‘B7 backbone. The code base is intentionally minimalâ€”no external experiment managersâ€”so that newcomers can trace every operation from raw JPGs âœ cropped datasets âœ PyTorch DataLoaders âœ training âœ evaluation.

âœ¨ Key Features

Component

File(s)

Purpose

Data augmentation

aug_img.py

Generates balanced train/validate/test splits by random cropping or fullâ€‘frame export of source SEM images. Handles test/val percentages and perâ€‘class stratification.

Config registry

config.py

Central place to register dataset / version pairs and override hyperâ€‘parameters (LR, epochs, batch size, etc.).

Dataset wrapper

datasets.py

Custom SEMDataset that assigns integer labels, supports deterministic seeding, and returns file names alongside tensors.

Training loop

train.py

Singleâ€‘GPU (or CPU) training with EfficientNetâ€‘B7, live accuracy/loss tracking, bestâ€‘model checkpointing, and PNG learningâ€‘curve export.

Inference & metrics

test.py

Loads the saved checkpoint, predicts on the test set, writes a CSV with perâ€‘image results, and visualises a confusion matrix + classification report.

Utility helpers

utils.py

Normalisation statistics, DataLoader assembly, criterion/optimizer factories, and accuracy helpers.

ğŸ—‚ Repository Layout

.
â”œâ”€â”€ data/                 # Autoâ€‘generated datasets & artefacts
â”‚   â””â”€â”€ example_v1/       #  â†³ train/validate/test JPGs + outputs
â”œâ”€â”€ source/               # Raw SEM images arranged by class label
â”œâ”€â”€ aug_img.py            # Dataâ€‘set builder
â”œâ”€â”€ config.py             # Hyperâ€‘parameter registry
â”œâ”€â”€ datasets.py           # PyTorch Dataset
â”œâ”€â”€ train.py              # Training script
â”œâ”€â”€ test.py               # Evaluation script
â”œâ”€â”€ utils.py              # Helper functions
â””â”€â”€ README.md             # (this file)

TipKeep your raw images under ./source/<class_label>/image.jpg so that the augmentation script can autoâ€‘detect labels.

âš¡ Quick Start

1.Â Install Dependencies

conda create -n semclass python=3.9 -y
conda activate semclass
pip install torch torchvision efficientnet_pytorch pandas seaborn tqdm pillow scikit-learn matplotlib

2.Â Prepare the Dataset

Generate 500 cropped images per class, reserving 10Â % for testing and 20Â % of the remainder for validation:

python aug_img.py source 500 -p 224 -t 10 -r 20 -n example -v True

Arguments

flag

default

meaning

path

source

Root folder of raw images

size

â€“

Number of generated images per class

-p / --pixel

True

Crop size (TrueÂ = half original, fullÂ = uncropped, or explicit pixels)

-t / --test

10

% of originals reserved for the test split

-r / --ratio

20

% (of remaining) reserved for validate split

-n / --name

â€“

Folder name under ./data/ for the new dataset

3.Â Register Hyperâ€‘parameters

Open config.py and add a new block or edit an existing one:

config = {
    "example": {
        "default": gen_default("example", size=500),
        "v1": {"lr": 3.5eâ€‘4, "epoch": 40}
    }
}

Each entry inherits from default and is merged via get_config(dataset, version) during runtime.

4.Â Train

python train.py

The script internally loads:

dataset_name = "example"
version       = "v1"

Modify those variables or expose them via environment variables if preferred.

Artifacts written to ./data/example/train/â€¦:

example_v1.pth â€“ best model weights (stateâ€‘dict)

example_v1.png â€“ accuracy/loss curves

5.Â Evaluate

python test.py

Outputs:

Confusionâ€‘matrix plot (onâ€‘screen)

example_v1.csv â€“ perâ€‘image predictions, groundâ€‘truth and pass/fail flag

Console classification report (precision, recall, F1)

ğŸ”§ Customisation Guide

What you want

Where to change

Use a different backbone

Replace EfficientNet.from_pretrained / .from_name in train.py & test.py.

Add data augmentation

Extend the train_img_transforms pipeline in utils.py.

Switch optimiser / loss

Add cases to utils.loss_fn & utils.optimize_fn, then reference in config.py.

Normalise inputs

Set "normalize": True in your config version; statistics are autoâ€‘computed.

Multiâ€‘GPU

Wrap the model in torch.nn.DataParallel before training.

ğŸ“Š Reproducibility

Deterministic seeds applied to PythonÂ random, NumPy, and PyTorch.

SEMDataset accepts a fixed seed to ensure identical random crops across runs.

ğŸ“ License

This repository is released under the MIT Licenseâ€”see LICENSE for details.

ğŸ¤ Acknowledgements

EfficientNetâ€‘Pytorch for the backbone implementation.

Original SEM datasets provided by the MII Research Lab.
